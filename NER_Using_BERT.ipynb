{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dependencies"
      ],
      "metadata": {
        "id": "NZr3Kdj0rO8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us first check the GPU resource available\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU4sNbF0bhp4",
        "outputId": "95c8ef8a-8678-4939-f568-8ed9cdff9ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 19 08:33:35 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8              17W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTSHUCoSq38l"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets tokenizer seqeval -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U -q\n",
        "!pip install transformers[torch] -q"
      ],
      "metadata": {
        "id": "V6c-7LsQQTUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from datasets import load_metric\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "mppDrDZEPCr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- # NER and POS Theory -->\n",
        "# Name Entity Recognition\n",
        "This is quite an important topic in the field of NLP, wherein it's core focus lies in identifying and classifying specific types of information present in the textual data. Basically, it can be viewed as a highlighter for important things in the given text, with the help of which machine can build a better context as it tries to understand data.\n",
        "\n",
        "Primarily, it does two things :     \n",
        "1. **Identification** : It scans thorugh the text and pinpoints words and phrases that represent specific entities, such as :     \n",
        "  * Names of the Person\n",
        "  * Organizations\n",
        "  * Locations\n",
        "  * Dates\n",
        "  * Times\n",
        "  * Quantities\n",
        "\n",
        "2. **Classification** : This process also enables to classify a given word/token into categories and label them, which aid the machine to understand the nature of information they've found.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iEks9-zZsl9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part of Speech\n",
        "Part-of-Speech (POS) tagging is a fundamental building block of many NLP tasks, which basically is like sorting words into grammatical buckets to understand their function within a sentence.\n",
        "\n",
        "It works in the following manner :\n",
        "\n",
        "1. **Assigning Labels**: Each word in a sentence is assigned a label corresponding to its grammatical category. Common POS tags include:\n",
        "\n",
        "  * **Noun (NN)**\n",
        "  * **Verb (VB)**\n",
        "  * **Adjective (JJ)**\n",
        "  * **Adverb (RB)**\n",
        "  * **Pronoun (PRP)**\n",
        "  * **Preposition (IN)**\n",
        "  * **Conjunction (CC)**\n",
        "\n",
        "By understanding the grammatical role of each word, NLP applications can achieve better performance in tasks such as machine translation, information retrieval, syntactic and semantic analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jvp5qrWnz-pR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset\n",
        "For this project, we will be using the **CoNLL-2003** dataset. The shared task of CoNLL-2003 concerns language-independent named entity recognition, where the concentrate is on four types of named entities:\n",
        "\n",
        "* Persons\n",
        "* Locations\n",
        "* Organizations\n",
        "* Names of miscellaneous entities that do not belong to the previous three groups.\n",
        "\n",
        "You can check it out [here](https://huggingface.co/datasets/eriktks/conll2003)"
      ],
      "metadata": {
        "id": "T9NivAUQr-XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003 = datasets.load_dataset(\"conll2003\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQHm6Kf8rvAr",
        "outputId": "559c5b7c-9d9f-42ec-91c5-c2de443098ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now view at our data and how it is distributed."
      ],
      "metadata": {
        "id": "shTUa77-uAVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYTciPrhsPAd",
        "outputId": "d67dc222-3918-4bfe-ef3a-71bccc60340b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also see the description of the datasets, as show below."
      ],
      "metadata": {
        "id": "Na4KT_0gxGMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data\")\n",
        "print(conll2003[\"train\"].description)\n",
        "print(\"---------------------------------------------------------------------------------------\")\n",
        "print(\"Validation Data\")\n",
        "print(conll2003[\"validation\"].description)\n",
        "print(\"---------------------------------------------------------------------------------------\")\n",
        "print(\"Test Data\")\n",
        "print(conll2003[\"test\"].description)\n",
        "print(\"---------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU4BpjgquOIa",
        "outputId": "42025ff0-007b-4cca-9edf-0ca806ff6608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data\n",
            "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\n",
            "four types of named entities: persons, locations, organizations and names of miscellaneous entities that do\n",
            "not belong to the previous three groups.\n",
            "\n",
            "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\n",
            "a separate line and there is an empty line after each sentence. The first item on each line is a word, the second\n",
            "a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\n",
            "and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\n",
            "if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\n",
            "B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\n",
            "tagging scheme, whereas the original dataset uses IOB1.\n",
            "\n",
            "For more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\n",
            "\n",
            "---------------------------------------------------------------------------------------\n",
            "Validation Data\n",
            "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\n",
            "four types of named entities: persons, locations, organizations and names of miscellaneous entities that do\n",
            "not belong to the previous three groups.\n",
            "\n",
            "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\n",
            "a separate line and there is an empty line after each sentence. The first item on each line is a word, the second\n",
            "a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\n",
            "and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\n",
            "if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\n",
            "B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\n",
            "tagging scheme, whereas the original dataset uses IOB1.\n",
            "\n",
            "For more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\n",
            "\n",
            "---------------------------------------------------------------------------------------\n",
            "Test Data\n",
            "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\n",
            "four types of named entities: persons, locations, organizations and names of miscellaneous entities that do\n",
            "not belong to the previous three groups.\n",
            "\n",
            "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\n",
            "a separate line and there is an empty line after each sentence. The first item on each line is a word, the second\n",
            "a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\n",
            "and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\n",
            "if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\n",
            "B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\n",
            "tagging scheme, whereas the original dataset uses IOB1.\n",
            "\n",
            "For more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\n",
            "\n",
            "---------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Model\n",
        "For this, we will be using the **BERT** model as our base model, on top of which we will be training our custom data.\n",
        "\n",
        "It's a bidirectional transformer pretrained using a combination of masked language modeling objective and next sentence prediction on a large corpus comprising the Toronto Book Corpus and Wikipedia. You can read more about it [here](https://arxiv.org/pdf/1810.04805).\n",
        "\n",
        "BERT, despite being a language model (LM) (not a large language model, LLM), can perform well on NER data due to its  bidirectional training  mechanism. This allows it to capture contextual relationships between words in a sentence, even when processing them from left to right, which is crucial for tasks like NER."
      ],
      "metadata": {
        "id": "agrPPQ-Mx6QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model)"
      ],
      "metadata": {
        "id": "Ui7WvvaExNg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now view the data which is used in the BERT Model."
      ],
      "metadata": {
        "id": "KN9kJPMe1rBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = conll2003[\"train\"][0][\"tokens\"]\n",
        "example_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVdZR6fjyjoI",
        "outputId": "39e591f3-9929-4953-b64d-2bd73cd32d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_example_id = tokenizer(example_text, is_split_into_words=True)\n",
        "tokenizer_example_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utDB7q7r2FTj",
        "outputId": "551a270e-23ed-4cc8-dcfe-2dd714660dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = tokenizer.convert_ids_to_tokens(tokenizer_example_id[\"input_ids\"])\n",
        "example_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39PKTZPb2P6m",
        "outputId": "a3003f5b-058a-4924-af6d-dd3b6e4c31c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'eu',\n",
              " 'rejects',\n",
              " 'german',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'british',\n",
              " 'lamb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, when BERT converts a text into tokens, it adds a \"**[CLS]**\" and \"**[SEP]**\" at the beginning and end of the data.\n",
        "\n",
        "Here, **[CLS]** stands for \"classification\" and is used as the first token for classification tasks. **[SEP]** stands for \"separator\" and is used to separate different sentences.\n",
        "\n",
        "Therefore, we also need our data set to have adjusted for these values as we aim to fine tune BERT on this data. Let us use a function to modify our data in the same way."
      ],
      "metadata": {
        "id": "lqmoBHPD2dx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "\n",
        "    #Tokeinze IDs\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "\n",
        "\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        \"\"\"\n",
        "        With this, we return a list mapping of the tokens to their\n",
        "        actual word in the initial sentence. The output is a list indicating the word corresponding to each token.\n",
        "        \"\"\"\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        \"\"\"\n",
        "        Now, there are special tokens like '' and '<\\s>' which are mapped to None.\n",
        "        We need to set the label to -100 so they are automatically ignored in the loss function at the time of training.\n",
        "        \"\"\"\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)   # Set '–100' as the label for these special tokens\n",
        "\n",
        "            #For the other tokens in a word, we set the label to either the current label or -100, depending on the label_all_tokens flag.\n",
        "\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # If current word_idx is != previous_word_idx, then it's the most regular case for which we can add the corresponding token\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                # To take care of sub-words which have the same word_idx,\n",
        "                # we set -100 as well for them, but only if label_all_tokens == False\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "                # Finally, we mask the subword representations after the first subword\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "eB_rJ0qULmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how the data is aligned to the labels, we can look at this example below."
      ],
      "metadata": {
        "id": "ICsghvcmLxXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = tokenize_and_align_labels(conll2003[\"train\"][0:1])\n",
        "\n",
        "print(\"Tokens---------------------------------->Labels\")\n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(example[\"input_ids\"][0]),example[\"labels\"][0]):\n",
        "    print(f\"{token:-<40} {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IJkrtXhMLpY",
        "outputId": "5c8c0957-eb12-4e3a-e803-874c83197a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens---------------------------------->Labels\n",
            "[CLS]----------------------------------- -100\n",
            "eu-------------------------------------- 3\n",
            "rejects--------------------------------- 0\n",
            "german---------------------------------- 7\n",
            "call------------------------------------ 0\n",
            "to-------------------------------------- 0\n",
            "boycott--------------------------------- 0\n",
            "british--------------------------------- 7\n",
            "lamb------------------------------------ 0\n",
            ".--------------------------------------- 0\n",
            "[SEP]----------------------------------- -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now go ahead and map this data with our function to convert it into the desired format."
      ],
      "metadata": {
        "id": "0tSrj2MfNBZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "id": "n7vqEdIiNLm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can go ahead and set the model."
      ],
      "metadata": {
        "id": "63d0zXcgOJPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(conll2003[\"train\"].features[\"ner_tags\"].feature.names)"
      ],
      "metadata": {
        "id": "UXIDF35COQtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(model, num_labels=num_labels).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rujcdh_2OPUu",
        "outputId": "577eb87f-f5f9-4ad1-bfc1-0d401ab7c709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model on Custom Data\n",
        "Let us load the arugments and the metrics required for evaluation."
      ],
      "metadata": {
        "id": "2Q9NMcGJO28k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args=TrainingArguments(\n",
        "    \"test-ner\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDjE5ZWJPQLI",
        "outputId": "9f8859c5-8924-472e-a165-2db101f44c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric Evaluation using SequeVal\n",
        "Here, we will be using the **Seqeval** metric, which is a Python framework for sequence labeling evaluation. seqeval can evaluate the performance of chunking tasks such as named-entity recognition, part-of-speech tagging, semantic role labeling and so on."
      ],
      "metadata": {
        "id": "4OpBnj49Y5qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = datasets.load_metric(\"seqeval\",trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeYwcr-SRDd5",
        "outputId": "e57f9afe-f6e1-43b2-e2ce-9e4deda107f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-66cc329c58b9>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\",trust_remote_code=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
        "labels_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpW6Y_EcVBy4",
        "outputId": "88adbd55-4156-4091-bac7-b2630087a116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows the possible outcome labels that will be predicted for a sentence, where they mean :\n",
        "\n",
        "1. **O**: This tag is used for tokens that are Outside of any named entity.\n",
        "2. **B-PER**: This tag is used to mark the Beginning of a Person named entity.\n",
        "3. **I-PER**: This tag is used to mark the Inside of a Person named entity.\n",
        "4. **B-ORG**: This tag is used to mark the Beginning of an Organization named entity.\n",
        "5. **I-ORG**: This tag is used to mark the Inside of an Organization named entity.\n",
        "6. **B-LOC**: This tag is used to mark the Beginning of a Location named entity.\n",
        "7. **I-LOC**: This tag is used to mark the Inside of a Location named entity.\n",
        "8. **B-MISC**: This tag is used to mark the Beginning of a Miscellaneous named entity.\n",
        "9. **I-MISC**: This tag is used to mark the Inside of a Miscellaneous named entity."
      ],
      "metadata": {
        "id": "MoVihx89VbNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = conll2003[\"train\"][1002]\n",
        "label_ids = example[\"ner_tags\"]\n",
        "example_labels = [labels_list[i] for i in label_ids]\n",
        "example_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5784734xVB1K",
        "outputId": "42ea7425-2d6b-44da-ec89-08141f8679e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if we look at the real sentence."
      ],
      "metadata": {
        "id": "Me2kZBq0WcNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TahILlEhVBwf",
        "outputId": "622b3a1a-8239-4bca-8e9a-82717aca4f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ONE', 'ROMANIAN', 'DIES', 'IN', 'BUS', 'CRASH', 'IN', 'BULGARIA', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here, it says that the word \"Romanian\" is the beginning of a miscellaneous enity and \"Bulgaria\" is the beginning of a location enity. Now with that, let us see how the metric works. For that, let us assume our model predicted the following :"
      ],
      "metadata": {
        "id": "O2qtJKCLWnir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']**\n",
        "\n",
        "Let us evaluate how that would be evaluated and what score it yields."
      ],
      "metadata": {
        "id": "HP60N5t7XWWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[example_labels], references=[[\"O\",\"B-LOC\",\"O\",\"O\",\"O\",\"O\",\"O\",\"B-LOC\",\"O\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNX1EmNUV-Wk",
        "outputId": "bb6e972a-223f-40f6-f8bc-f11a71332be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC': {'precision': 1.0,\n",
              "  'recall': 0.5,\n",
              "  'f1': 0.6666666666666666,\n",
              "  'number': 2},\n",
              " 'MISC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
              " 'overall_precision': 0.5,\n",
              " 'overall_recall': 0.5,\n",
              " 'overall_f1': 0.5,\n",
              " 'overall_accuracy': 0.8888888888888888}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, it evaluates each NER tag and gives a respective score for this. With this knowledge, let us build a method which can evaluate and yield the overal score."
      ],
      "metadata": {
        "id": "jxyyTM0PXMw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # Here, the logits and the probabilities are in the same order, hence there is no need to apply softmax to them\n",
        "\n",
        "    # Now, we will remove all the values where the label is \"-100\"\n",
        "    predictions = [\n",
        "        [labels_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "        [labels_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "\n",
        "    return {\n",
        "          \"precision\": results[\"overall_precision\"],\n",
        "          \"recall\": results[\"overall_recall\"],\n",
        "          \"f1\": results[\"overall_f1\"],\n",
        "          \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }"
      ],
      "metadata": {
        "id": "mdvgBudxadsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator=DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "Js-udV9eadpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer\n",
        "Now, we can go ahead and build the Trainer."
      ],
      "metadata": {
        "id": "syXO7Qi0TVfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "              model,\n",
        "              args,\n",
        "              train_dataset=tokenized_datasets[\"train\"],\n",
        "              eval_dataset=tokenized_datasets[\"validation\"],\n",
        "              data_collator=data_collator,\n",
        "              tokenizer=tokenizer,\n",
        "              compute_metrics=compute_metrics\n",
        "          )"
      ],
      "metadata": {
        "id": "p9-Jk0E-c9OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "B-NNreH1bRr2",
        "outputId": "0fb60be9-6f2d-4407-c2d6-1b60922e5a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4390/4390 19:00, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.221100</td>\n",
              "      <td>0.063035</td>\n",
              "      <td>0.914687</td>\n",
              "      <td>0.925942</td>\n",
              "      <td>0.920280</td>\n",
              "      <td>0.982144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.045500</td>\n",
              "      <td>0.056911</td>\n",
              "      <td>0.933517</td>\n",
              "      <td>0.947198</td>\n",
              "      <td>0.940308</td>\n",
              "      <td>0.985750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.024200</td>\n",
              "      <td>0.057938</td>\n",
              "      <td>0.938834</td>\n",
              "      <td>0.949547</td>\n",
              "      <td>0.944160</td>\n",
              "      <td>0.986560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.013900</td>\n",
              "      <td>0.060980</td>\n",
              "      <td>0.934177</td>\n",
              "      <td>0.949435</td>\n",
              "      <td>0.941744</td>\n",
              "      <td>0.986020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.009400</td>\n",
              "      <td>0.062548</td>\n",
              "      <td>0.941424</td>\n",
              "      <td>0.951113</td>\n",
              "      <td>0.946244</td>\n",
              "      <td>0.986767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4390, training_loss=0.05012114933248533, metrics={'train_runtime': 1141.8752, 'train_samples_per_second': 61.482, 'train_steps_per_second': 3.845, 'total_flos': 1702317283240608.0, 'train_loss': 0.05012114933248533, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"NER_Model_2.0\")\n",
        "tokenizer.save_pretrained(\"NER_Tokenizer_2.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzoTxlacJzT",
        "outputId": "38463698-e2b0-411c-bbce-ffce7a9a813d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('NER_Tokenizer_2.0/tokenizer_config.json',\n",
              " 'NER_Tokenizer_2.0/special_tokens_map.json',\n",
              " 'NER_Tokenizer_2.0/vocab.txt',\n",
              " 'NER_Tokenizer_2.0/added_tokens.json',\n",
              " 'NER_Tokenizer_2.0/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, before we proceed, let us have a quick look at the configuration of the model."
      ],
      "metadata": {
        "id": "pZ80siqakJLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = json.load(open(\"/content/NER_Model_2.0/config.json\"))\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3BUY4EGkJB1",
        "outputId": "a6c31539-8eb7-48c8-e0d0-671ff90522a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_name_or_path': 'bert-base-uncased',\n",
              " 'architectures': ['BertForTokenClassification'],\n",
              " 'attention_probs_dropout_prob': 0.1,\n",
              " 'classifier_dropout': None,\n",
              " 'gradient_checkpointing': False,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'id2label': {'0': 'LABEL_0',\n",
              "  '1': 'LABEL_1',\n",
              "  '2': 'LABEL_2',\n",
              "  '3': 'LABEL_3',\n",
              "  '4': 'LABEL_4',\n",
              "  '5': 'LABEL_5',\n",
              "  '6': 'LABEL_6',\n",
              "  '7': 'LABEL_7',\n",
              "  '8': 'LABEL_8'},\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'label2id': {'LABEL_0': 0,\n",
              "  'LABEL_1': 1,\n",
              "  'LABEL_2': 2,\n",
              "  'LABEL_3': 3,\n",
              "  'LABEL_4': 4,\n",
              "  'LABEL_5': 5,\n",
              "  'LABEL_6': 6,\n",
              "  'LABEL_7': 7,\n",
              "  'LABEL_8': 8},\n",
              " 'layer_norm_eps': 1e-12,\n",
              " 'max_position_embeddings': 512,\n",
              " 'model_type': 'bert',\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'pad_token_id': 0,\n",
              " 'position_embedding_type': 'absolute',\n",
              " 'torch_dtype': 'float32',\n",
              " 'transformers_version': '4.41.2',\n",
              " 'type_vocab_size': 2,\n",
              " 'use_cache': True,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see above, the labels which we want to get are not enabled in the configuration of the model. The labels which are there in the dataset on which our model is trained, are not present here. So let us go ahead and set the same."
      ],
      "metadata": {
        "id": "NAtfB949ksEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    str(i): label for i,label in enumerate(labels_list)\n",
        "}\n",
        "\n",
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyHJh4SBkI_Y",
        "outputId": "e111cde5-2bff-4b13-b031-3adec3f5f2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'O',\n",
              " '1': 'B-PER',\n",
              " '2': 'I-PER',\n",
              " '3': 'B-ORG',\n",
              " '4': 'I-ORG',\n",
              " '5': 'B-LOC',\n",
              " '6': 'I-LOC',\n",
              " '7': 'B-MISC',\n",
              " '8': 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {\n",
        "    label: str(i) for i,label in enumerate(labels_list)\n",
        "}\n",
        "\n",
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMq5TxpqnroG",
        "outputId": "db8487f5-6b48-47fb-8d03-d0bc70fa6dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': '0',\n",
              " 'B-PER': '1',\n",
              " 'I-PER': '2',\n",
              " 'B-ORG': '3',\n",
              " 'I-ORG': '4',\n",
              " 'B-LOC': '5',\n",
              " 'I-LOC': '6',\n",
              " 'B-MISC': '7',\n",
              " 'I-MISC': '8'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"id2label\"] = id2label\n",
        "config[\"label2id\"] = label2id"
      ],
      "metadata": {
        "id": "OFil8GT7kI9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final configurations of our model are as shown below."
      ],
      "metadata": {
        "id": "mV_x-r5jlz8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWi9UHyhkIrR",
        "outputId": "cfcfc647-6e95-499d-f4ec-9f3685898cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_name_or_path': 'bert-base-uncased',\n",
              " 'architectures': ['BertForTokenClassification'],\n",
              " 'attention_probs_dropout_prob': 0.1,\n",
              " 'classifier_dropout': None,\n",
              " 'gradient_checkpointing': False,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'id2label': {'0': 'O',\n",
              "  '1': 'B-PER',\n",
              "  '2': 'I-PER',\n",
              "  '3': 'B-ORG',\n",
              "  '4': 'I-ORG',\n",
              "  '5': 'B-LOC',\n",
              "  '6': 'I-LOC',\n",
              "  '7': 'B-MISC',\n",
              "  '8': 'I-MISC'},\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'label2id': {'O': '0',\n",
              "  'B-PER': '1',\n",
              "  'I-PER': '2',\n",
              "  'B-ORG': '3',\n",
              "  'I-ORG': '4',\n",
              "  'B-LOC': '5',\n",
              "  'I-LOC': '6',\n",
              "  'B-MISC': '7',\n",
              "  'I-MISC': '8'},\n",
              " 'layer_norm_eps': 1e-12,\n",
              " 'max_position_embeddings': 512,\n",
              " 'model_type': 'bert',\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'pad_token_id': 0,\n",
              " 'position_embedding_type': 'absolute',\n",
              " 'torch_dtype': 'float32',\n",
              " 'transformers_version': '4.41.2',\n",
              " 'type_vocab_size': 2,\n",
              " 'use_cache': True,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(config,open(\"/content/NER_Model_2.0/config.json\",\"w\"))"
      ],
      "metadata": {
        "id": "Y-6jcLCemvC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Pipeline\n",
        "Let us now go ahead and build the pipeline for making predictions."
      ],
      "metadata": {
        "id": "ASkPLr-Uh-xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_finetuned = AutoModelForTokenClassification.from_pretrained(\"/content/NER_Model_2.0\")\n",
        "tokenizer_finetuned = BertTokenizerFast.from_pretrained(\"/content/NER_Tokenizer_2.0\")\n",
        "\n",
        "nlp_pipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model= model_finetuned,\n",
        "    tokenizer=tokenizer_finetuned\n",
        "    )"
      ],
      "metadata": {
        "id": "RmsMxKtWhy7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now take an example to work with, and make a prediction on the same."
      ],
      "metadata": {
        "id": "3Qq1cB7Gi25o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Ben is a college student at UCLA\"\n",
        "nlp_pipeline(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxcGvWb7izi0",
        "outputId": "e00192b9-0307-483f-853a-dca30c231615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.9949121,\n",
              "  'index': 1,\n",
              "  'word': 'ben',\n",
              "  'start': 0,\n",
              "  'end': 3},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.91264635,\n",
              "  'index': 7,\n",
              "  'word': 'ucla',\n",
              "  'start': 28,\n",
              "  'end': 32}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example2 = \"Apple launched a Mac with the M3 chip\"\n",
        "nlp_pipeline(example2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYIBJagQuhU2",
        "outputId": "0529ab27-3056-4a8e-c669-518c2a9aa862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.99727315,\n",
              "  'index': 1,\n",
              "  'word': 'apple',\n",
              "  'start': 0,\n",
              "  'end': 5},\n",
              " {'entity': 'B-MISC',\n",
              "  'score': 0.94175667,\n",
              "  'index': 4,\n",
              "  'word': 'mac',\n",
              "  'start': 17,\n",
              "  'end': 20},\n",
              " {'entity': 'B-MISC',\n",
              "  'score': 0.9121459,\n",
              "  'index': 7,\n",
              "  'word': 'm3',\n",
              "  'start': 30,\n",
              "  'end': 32}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example3 = \"EU rejects German call to boycott British lamb.\"\n",
        "nlp_pipeline(example3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJm3f_xSvktf",
        "outputId": "59af845d-a4ac-4824-95dc-d9a2332d682d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.9988004,\n",
              "  'index': 1,\n",
              "  'word': 'eu',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity': 'B-MISC',\n",
              "  'score': 0.9991093,\n",
              "  'index': 3,\n",
              "  'word': 'german',\n",
              "  'start': 11,\n",
              "  'end': 17},\n",
              " {'entity': 'B-MISC',\n",
              "  'score': 0.99863094,\n",
              "  'index': 7,\n",
              "  'word': 'british',\n",
              "  'start': 34,\n",
              "  'end': 41}]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example4 =\"Microsoft Windows created their software in 2000\"\n",
        "nlp_pipeline(example4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmZ50Qkjvy9Z",
        "outputId": "00c37002-36ef-40ed-b7fb-09b3c5369b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.9977283,\n",
              "  'index': 1,\n",
              "  'word': 'microsoft',\n",
              "  'start': 0,\n",
              "  'end': 9},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.98648596,\n",
              "  'index': 2,\n",
              "  'word': 'windows',\n",
              "  'start': 10,\n",
              "  'end': 17}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example5 = \"Mark is a founder of facebook and microsoft\"\n",
        "nlp_pipeline(example5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bERhL184v92U",
        "outputId": "e1e715c4-2f05-4d37-86d8-765b738eedae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.9974425,\n",
              "  'index': 1,\n",
              "  'word': 'mark',\n",
              "  'start': 0,\n",
              "  'end': 4},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.99797136,\n",
              "  'index': 6,\n",
              "  'word': 'facebook',\n",
              "  'start': 21,\n",
              "  'end': 29},\n",
              " {'entity': 'B-ORG',\n",
              "  'score': 0.9970747,\n",
              "  'index': 8,\n",
              "  'word': 'microsoft',\n",
              "  'start': 34,\n",
              "  'end': 43}]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "In this project, we saw the two key NLP techniques: Named Entity Recognition (NER) and Part-of-Speech (POS) tagging. NER helps machines understand text by identifying important details like names and locations. POS tagging assigns grammatical labels to words, aiding tasks like translation and analysis.\n",
        "\n",
        "We explored this with a custom NER system using the CoNLL-2003 dataset and the BERT model. This is just a taste of NLP's potential, fueled by deep learning and ever-growing data, to revolutionize human-computer interaction. You can check out this notebook and experiment for yourself [here](https://colab.research.google.com/drive/1HdardYoLm9j30bcOU_U9EJrhOVgYcMDG?usp=sharing)."
      ],
      "metadata": {
        "id": "TzignTuCwvuW"
      }
    }
  ]
}